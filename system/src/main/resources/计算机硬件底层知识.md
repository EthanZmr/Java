### CPU乱序执行

CPU在进行读等待的同时执行指令, 是 CPU 乱序的根源. 本质上不是乱, 而是提高效率

CPU内存速度比100:1

### 对象的创建过程

```java
class T {
    int m = 8;
}
T t = new T();
```

汇编码:
```asm
0 new #2 <T>   # 开辟一块内存空间
3 dup(duplicate) # 复制一个在栈帧中指向新开辟的内存空间的引用
4 invokespecial #3 <T.<init>> # 从栈帧中弹出一个引用, 赋值给局部变量表中的第一个位置， 第 0 个位置是 this
7 astore_1 # 这条指令结束之后, 变量 t 指向新对象
8 return # 返回
```

上面的流程是可以进行指令重排序的, 所以多线程环境下, 
一个线程是有可能指向半初始化的对象的(开辟了内存空间, 但是还没有赋值)

因此在 DCL 单例中是需要volatile关键字来修饰的.

CPU 层面如何禁止重排序?

**内存屏障**

intel CPU: lfence(load), mfence(mix), sfence(save) 原语 或者锁总线

有序性保障：

intel lock汇编指令：
    原子指令, 如x86上的"lock..."指令是一个Full Barrier, 
执行时会锁住内存子系统来确保执行顺序, 甚至跨越多个 CPU. 
software Locks通常使用了内存屏障或原子指令来实现变量可见性
和保持程序顺序.

sfence: 在sfence指令前的写操作当必须在sfence指令后的写操作前完成.
lfence: 在lfence指令前的读操作当必须在lfence指令后的读操作前完成.
mfence: 在mfence指令前的读写操作当必须在mfence指令后的读写操作前完成.

#### JSR内存屏障
* LoadLoad屏障:
  * LoadLoad后面的读取指令操作前, 保证 LoadLoad 前面的读取指令先执行完
* StoreStore屏障:
  * StoreStore后面的写操作前, 保证 StoreStore 前面的写操作先执行完

* LoadStore屏障:
  * LoadStore后面的写操作前, 保证 LoadStore 前面的读操作先执行完

* StoreLoad屏障:
  * StoreLoad后面的读操作前, 保证 StoreLoad 前面的写操作先执行完

JVM层面的 volatile 实现细节：
```
StoreStoreBarrier<br>
volatile 写操作<br>
StoreLoadBarrier


LoadLoadBarrier<br>
volatile 读操作<br>
LoadStoreBarrier
```

本质上还是Lock 指令!!!

* as if serial:
  * 不管如何重排序, 单线程执行结果不会改变
* happens before:
  * 

#### WC Write Combining 合并写技术

为了提高写效率: CPU 在写入L1时, 同时用 WC 写入L2

在CPU和L1缓存之间存在Load Buffer, Store Buffer, WC Buffer.

WC Buffer大小为 4 个字节.

#### NUMA (Non Uniform Memory Access) 非统一访问内存
UMA: 不易扩展, CPU 数量增多后引起内存访问冲突加剧, CPU 的很多资源花在争抢内存地址上面。4 颗左右比较合适.

分配内存会优先分配该线程所在 CPU 的最近内存

### OS基础

kernel: CPU调度, 内存管理, 【中断处理、设备驱动】, 管理文件系统, 【应用管理、进程调度】

* 宏内核：所有的功能集成到 kernel 中放到一块内存空间中. (响应稍慢, 弹性部署, 灵活)
* 微内核：kernel 只有一个进程调度功能. 远程调度其他进程完成用户的请求. (响应快, 需要资源大, 不能够灵活部署)

#### VMM 虚拟机监控
硬件资源过剩时 通过 VMM 模拟多个操作系统

Linux使用 ring0 和 ring3级别代表内核态和用户态

内核执行的操作->通过系统函数暴露 read write sendfile...


