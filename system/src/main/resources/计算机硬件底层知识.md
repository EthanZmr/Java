## CPU乱序执行

CPU在进行读等待的同时执行指令, 是 CPU 乱序的根源. 本质上不是乱, 而是提高效率

CPU内存速度比100:1

### 对象的创建过程

```java
class T {
    int m = 8;
}
T t = new T();
```

汇编码:
```asm
0 new #2 <T>   # 开辟一块内存空间
3 dup(duplicate) # 复制一个在栈帧中指向新开辟的内存空间的引用
4 invokespecial #3 <T.<init>> # 从栈帧中弹出一个引用, 赋值给局部变量表中的第一个位置， 第 0 个位置是 this
7 astore_1 # 这条指令结束之后, 变量 t 指向新对象
8 return # 返回
```

上面的流程是可以进行指令重排序的, 所以多线程环境下, 
一个线程是有可能指向半初始化的对象的(开辟了内存空间, 但是还没有赋值)

因此在 DCL 单例中是需要volatile关键字来修饰的.

CPU 层面如何禁止重排序?

**内存屏障**

intel CPU: lfence(load), mfence(mix), sfence(save) 原语 或者锁总线

有序性保障：

intel lock汇编指令：
    原子指令, 如x86上的"lock..."指令是一个Full Barrier, 
执行时会锁住内存子系统来确保执行顺序, 甚至跨越多个 CPU. 
software Locks通常使用了内存屏障或原子指令来实现变量可见性
和保持程序顺序.

sfence: 在sfence指令前的写操作当必须在sfence指令后的写操作前完成.
lfence: 在lfence指令前的读操作当必须在lfence指令后的读操作前完成.
mfence: 在mfence指令前的读写操作当必须在mfence指令后的读写操作前完成.

#### JSR内存屏障
* LoadLoad屏障:
  * LoadLoad后面的读取指令操作前, 保证 LoadLoad 前面的读取指令先执行完
* StoreStore屏障:
  * StoreStore后面的写操作前, 保证 StoreStore 前面的写操作先执行完

* LoadStore屏障:
  * LoadStore后面的写操作前, 保证 LoadStore 前面的读操作先执行完

* StoreLoad屏障:
  * StoreLoad后面的读操作前, 保证 StoreLoad 前面的写操作先执行完

JVM层面的 volatile 实现细节：
```
StoreStoreBarrier<br>
volatile 写操作<br>
StoreLoadBarrier


LoadLoadBarrier<br>
volatile 读操作<br>
LoadStoreBarrier
```

本质上还是Lock 指令!!!

* as if serial:
  * 不管如何重排序, 单线程执行结果不会改变
* happens before:
  * 



